---
title: "String Manipulations and Regular Expressions"
author: "Greg Young and Anna Rouw"
date: "2021-06-30 and last compiled `r Sys.time`"
output: output_format: html_format
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Libraries and Functions

library(tidyverse)
library(rvest)
library(countrycode)

`%!in%` <- Negate("%in%") 

```

# Introduction (GY + AR)

In this lesson, we will go over some basic string manipulations (using the packages base and stringr), regular expressions, and a few examples. This hopefully will help when cleaning/manipulating using character data. For a cheatsheet on stringr and regular expressions, see here: <https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf>. 

# String Manipulations (GY)

Below are examples using string manipulations, with both base and stringr functions. These manipulations include detecting strings, finding string length, matching strings, extracting strings, sorting strings, duplicating strings, splitting strings, replacing strings, removing strings, and formatting strings. Below are examples of these manipulations (with examples in both base and stringr). For a reference on conversions between base and stringr, see here: <https://stringr.tidyverse.org/articles/from-base.html> 

```{r String Manipulations, include=FALSE}
# String Manipulations (GY)

conversion_example <- c("new jersey", "south central south carolina ", "southern california", "nebraska", "new amsterdam ave, new york city, new york state", "new mexico", "pennsylvania", "south dakota")

# Detecting strings 

### base
gregexpr("new", conversion_example)	

### base replicating stringr 
lapply(gregexpr("new", conversion_example), function(i) {
	out <- cbind(i, apply(cbind(i-1, attributes(i)$match.length), 1, sum))
	colnames(out) <- c("start", "end"); out[out < 0] <- NA
	return(out)
	})	

### stringr
str_locate_all(conversion_example, "new")

## Values
### base
grep("south", conversion_example, value = TRUE)	

### stringr
str_subset(conversion_example, "south")

## Indices
### base
grep("south", conversion_example)	

### stringr
str_which(conversion_example, "south")

## Logical vector
### base
grepl("south", conversion_example)	

### stringr
str_detect(conversion_example, "south")

# Finding string length

## base
nchar(conversion_example)	

## stringr
str_length(conversion_example)

# Matching strings

## base
regexec( "south", conversion_example) 
yes <- regexec( "south", conversion_example) 
regmatches(conversion_example, yes)

## stringr
str_match( conversion_example ,"south")

# Extracting strings
## Extract specific value
### base
yes <- regexpr( "south", conversion_example) 
regmatches(conversion_example, yes)

### stringr
str_extract( conversion_example ,"south")

## Extract by position
### base
substr(conversion_example, 2, 4)	

### stringr
str_sub(conversion_example, 2, 4)

# Sorting strings

## base
sort(conversion_example)

## stringr
str_sort(conversion_example)

# Duplicating strings

## base
strrep(conversion_example, 2)	

## stringr
str_dup(conversion_example, 2)

# Splitting strings

## base
strsplit(conversion_example, " ")

## stringr
str_split(conversion_example, " ")

# Replacing strings

## base
sub("south", "funfunfun", conversion_example)

## stringr
str_replace(conversion_example, "south", "funfunfun")

# Removing strings 

## base
sub("new", "", conversion_example)
gsub("new", "", conversion_example)

## stringr
str_remove(conversion_example, "new")
str_remove_all(conversion_example, "new")

# Formatting strings

## base
tolower(conversion_example)

## stringr
str_to_lower(conversion_example)

## base
tools::toTitleCase(conversion_example)

## stringr
str_to_title(conversion_example)

## base
toupper(conversion_example)	

## stringr
str_to_upper(conversion_example)

## base
trimws(conversion_example)

## stringr
str_trim(conversion_example)


```


# Regular Expressions (AR)

Regular expressions are a sequence of special characters to describe a text pattern. Regular expressions are not unique to R and are used across programming languages. We'll go over types of regular expressions before getting into more complicated examples. Regular expression topics to be covered include anchors, quantifiers, match characters, escaping, look-arounds, grouping, case insensitivity, 

```{r regex, echo = T}

## Code below

# Anchors
## Anchors allow you to find patterns at the start or end of a string

anchors_example <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

anchors_example[str_detect(anchors_example, "^J")] ## Find months that start with the letter J
anchors_example[str_detect(anchors_example, "er$")] ## Find months that end in 'er'

# Quantifiers
## Quantifiers allow you to define how many times to look for a certain pattern

quantifiers_example <- c("1", "2", "30000", "45600", "7836539273", "45", "150", "Anna")

str_extract(quantifiers_example, "[[:digit:]]?") ## Find digit of 0 or 1 length 
str_extract(quantifiers_example, "[[:digit:]]*") ## Find digit of any length (including 0)
str_extract(quantifiers_example, "[[:digit:]]+") ## Find digit of at least 1 length (does not include 0)
str_extract(quantifiers_example, "[[:digit:]]{2}") ## Find digit with at least 2 length
str_extract(quantifiers_example, "[[:digit:]]{3,}") ## Find digits greater than 99
str_extract(quantifiers_example, "[[:digit:]]{3,6}") ## Find digits with lengths between 3 and 6

# Match characters
## There are certain, pre-defined match characters that look for certain character types in a string.

match_character_example <- c("Alabama, 5%", "Florida 10.7%", "Colorado 7.1%", "West Virginia, 15.7%") 

### Numbers

str_extract_all(match_character_example, "[[:digit:]]+") ##Breaks up values when interrupted by another character type

### Punctuation

str_extract_all(match_character_example, "[[:punct:]]+")

### Letters

str_extract_all(match_character_example, "[[:alpha:]]+")

### Spaces

str_extract_all(match_character_example, "[[:space:]]+")

### Any character (except new lines -- \n)

str_extract(match_character_example, ".+")

### Other types -- lowercase, uppercase, blanks (tabs and spaces) and combinations (i.e. [[:alnum:]])

# Escaping
## Some characters, such as the $ anchor, are used to denote other patterns and do not represent the symbol itself. These characters, in order to be captured, must be escaped. We escape using the \

escape_example <- c("$4500", "(Hello)", "What is your favorite movie?")

str_extract(escape_example, "$") ## This will give us empty values since we have not escaped
str_extract(escape_example, "\\$")
str_extract(escape_example, "?") ## Should return an error since we have not escaped
str_extract(escape_example, "\\?")
str_extract(escape_example, "(") ## Should return an error since we have not escaped
str_extract(escape_example, "\\(")

## \ can also be used to describe a character type, such as digits or words.

escape_words_example <- "Dogs are the best"

str_extract_all(escape_words_example, "\\w+") ## Extracts all the words from the sentence.

# Look Arounds
## Look-arounds are very helpful to identify patterns before and/or after a certain string. 
### Look behind

look_behind_example <- c("KFF Employee ID: 98", "KFF Employee ID: 72", "KFF Employee ID: 43")

str_extract(look_behind_example, "(?<=KFF Employee ID: ).*")

## Look ahead

look_ahead_example <- c("Mr. Sam Smith", "Dr. Anthony Fauci", "Mrs. Rita Rooney")

str_extract(look_ahead_example, ".*\\.(?= )")

# Groups
## Grouping allows us to set order of evaluation when looking for patterns and add a bit of flexibility.

grouping_example <- c("Violet", "Vince", "Charlie", "Terry", "Vance", "Tanya", "Vicky Vaughn", "Vicky Blake")

str_extract(grouping_example, "^(V|T).*") ## Find names that start with V or T

str_extract(grouping_example, "^(V).*\\1.*") ## Allows us to reference previously created groups. The \\1 is referencing the  previous regex

# Case Insensitivity
## Ignore case

case_insenstive_example <- c("Medicare", "medicare")

str_extract(case_insenstive_example, "(?i)medicare")

# Alternates

alternates_example <- c("abc", "abc123", "abc123,.", "123,.", ",.", "123", "abc,. ", "abc 123 .,")

## Set parameters around your search

### Or logical operator

str_extract(alternates_example, "\\d+|[:punct:]+") ## Find first set of digits or punctuation (if both present, will return the first match)

### One of

str_extract(alternates_example, "[[:digit:][:punct:][:space:]]+") ## Lets you combine specific character types

### Anything but

str_extract(alternates_example, "[^[:alpha:]]+") ## Extract everything but alphabetic characters

### Range

str_extract(alternates_example, "[a-c]+")
str_extract(alternates_example, "[1-3]+")
str_extract(alternates_example, "[d-m]+")
str_extract(alternates_example, "[4-6]+")

```

# Examples (GY)

Walking through a few examples with string manipulations and regular expressions.

```{r examples, echo = T}

# id numbers 
id <- c("ID3445","WRT-3445","W3D-3445", "YH893","WR-902","WY9323","AO-394","A2-394","W2-657","ER-323","WP-434","YP-434")

# returns every element starting with W followed by 1 letter and then a dash
id[grep("^W[[:alpha:]]-", id)] 

# returns every element starting with W followed by 1 or more letters and then a dash
id[grep("^W[[:alpha:]]+-", id)] 

# returns every element starting with W followed by 1 or more of any character and then a dash
id[grep("^W.+-", id)]


# get the whole numbers
wn <- c("173.34","Deductible $1200", "21", "Copay")

# escape dollar sign and extract values
str_extract( wn ,"\\$\\d+") 

# escape dollar sign optional
str_extract( wn ,"\\$?\\d+") 

# extracts first word of element
str_extract( wn ,"[[:alpha:]]+") 

# correct state names
s <- c("District of\n Columbia", "South Carolina ","Texas", "Hawaii 50")

# replaces "\n"
str_replace_all(s, "\n", " ") 

# removes all non alpha or space characters
trimws(str_remove_all(s, "[^[:alpha:][:blank:]]")) 

# convert this to numbers
n <- c("1.2%","1.0%","3.9%","1.9%","5.6%","3.4%")

as.numeric(str_replace_all(n, "%", ""))
as.numeric(str_replace_all(n, "%", ""))/100


# convert multiple underscores into one underscore
x <- c( "var_1","var__2","var____3" ,"anoter_var__3")

# replace underscore with dot 
gsub("[[:punct:]]+", "\\.", x)

# extract value with look arounds
prem <- c("HMO Premium 456","HMO Premiums 789","Premiums are 345","999 Premiums this year are 443","555 Premiums this year were payed", "Deductible of 721 this year")

#use look behind for premium
str_extract( prem ,"(?<=Premium.{1,30}\\d{0})\\d+")
#use look behind for deductible
str_extract( prem ,"(?<=Deductible.{1,30}\\d{0})\\d+")
#use look ahead for number of premium
str_extract( prem ,"(?=.{1,30}Premium)\\d+")

### get rid of punctuation and numbers
wp <- c("Hospital.Names...3","State_ ", "George")

str_replace_all(wp, "[._ \\d]", " ")

### Convert this to a five digit zip code
zip <- c("91367-6798","91364-2792","4605-2792")

str_pad(str_extract( zip ,"\\d+(?=-)"), 5, pad = "0") 
str_pad(str_extract( zip ,"\\d+(?=-\\d{4})"), 5, pad = "0")


### Reduce this to First and last names 
fl <- c("Matthew T. Rae","Claxton, Gary", "Dr. Craig Palosky Esq.", "Dr. Chris Lee", "Damico, Anthony","Daniel McDermott Jr.")

# first names

str_trim(str_extract( fl ,"[[:Alpha:]]+\\s|[[:Alpha:]]+$"), side ="both") 
# first and last names
str_replace_all(str_trim(str_replace_all(fl, "[[:alpha:]]{1,3}\\.", ""), side ="both"), "[[:punct:]]", "")

# grouping - when you place parenthesis around something it keeps it as a seperate group 
# phone numbers 
pn <- c("202-555-4343","202-555-8434","555-8434","(434)555-4567","434-555-4567","434-555-4347","(202)555-4567","434-555-4347","(202)555-4567")

# recode phone numbers so they are in same format
str_replace_all(str_replace_all(pn, "\\(" , ""), "\\)", "-")  


```

## Real world example -- data cleaning (AR)

Going to be pulling data from each country's COVAX delivery web page. For reference, here is what Afghanistan's web page looks like: <https://www.gavi.org/covax-vaccine-roll-out/afghanistan>. The web pages have already been scraped for each country, but we will use string manipulations and regular expressions to extract the data from the messy text.

```{r real life example set up, include = F}

doses <- read.csv("L:/r_lessons/regex/Raw Data for Real World Example.csv")

```

```{r real life example data cleaning, echo = T}

library(RSelenium)

system("taskkill /im java.exe /f", intern=FALSE, ignore.stdout=FALSE) ## Make sure no other RSelenium program is running

rD <- rsDriver(browser = 'firefox') 

driver <- rD[['client']]

driver$navigate(doses$link[1]) ## See where the data is coming from

# Get country name from link

doses <- doses %>%
  mutate(country = str_to_title(str_extract(link, "(?<=out/).*(?=$)"))) %>%
  arrange(country)

doses <- doses %>%
  mutate(country = suppressWarnings(countrycode(country, origin = 'country.name', destination = 'country.name.en', nomatch = country))) ## clean up country names

# Get date of first delivery

doses$text[1] ## See what text of webpage looks like

doses <- doses %>%
  mutate(first_delivery_date = str_extract(text, "\\d{1,2}\\s{1}[[:alpha:]]*\\s{1}\\d{4}"))

doses <- doses %>%
  mutate(first_delivery_date = as.Date(first_delivery_date, format = "%d %B %Y")) ## Convert to a date. For reference, here are the date formats: https://www.r-bloggers.com/2013/08/date-formats-in-r/


# Find doses received

received <- doses %>%
  mutate(doses_received_text = str_extract(text, "(?<=Doses received).*(?=Doses allocated)") %>% trimws()) ## Find doses received text

received <- received %>%
  separate_rows(doses_received_text, sep = "vaccine") ## Sometimes a country has received multiple vaccine products, so we'll separate the text at the word 'vaccine'

received <- received %>%
  filter(str_detect(doses_received_text, "\\d")) ## Remove rows where there are no date

received <- received %>%
  mutate(doses_received = str_extract_all(doses_received_text, "\\d{1,3},\\d{3},\\d{3}|\\d{1,3},\\d{3}|\\d{1,3}\\.\\d{1,3}\\s{1}(?i)million|\\d{1,3}\\s{1}(?i)million(?=[:upper:])")) ## This is really complicated because the text is quite messy. You always want your more complicated regex first since once R finds a pattern, it will disregard the other regex patterns. 

received <- received %>%
  mutate(doses_received = str_remove_all(doses_received, "[,\\s]")) %>% ## Remove all spaces and commas
  mutate(doses_received = ifelse(str_detect(doses_received, "(?i)million"), ## Multiply by 1,000,000 if you find the word 'million'
                                 as.numeric(trimws(str_remove_all(doses_received, "(?i)million")))*1000000,
                                 as.numeric(trimws(doses_received))))

received <- received %>%
  mutate(vaccine_received = str_extract(doses_received_text, "(?<=\\d)\\s+.*(?=$)") %>% str_remove_all("million") %>% trimws())

received <- received %>%
  select(-doses_received_text, -link, -text) ## Do not need anymore

# Find doses allocated

allocations <- doses %>%
  mutate(doses_allocated_text = str_extract(text, "(?<=Doses allocated).*(?=$)"))

allocations <- allocations %>%
  separate_rows(doses_allocated_text, sep = "vaccine")

allocations <- allocations %>%
  filter(str_detect(doses_allocated_text, "\\d"))

allocations <- allocations %>%
  mutate(doses_allocated = str_extract_all(doses_allocated_text, "\\d{1,3},\\d{3},\\d{3}|\\d{1,3},\\d{3}|\\d{1,3}\\.\\d{1,3}\\s{1}(?i)million|\\d{1,3}\\s{1}(?i)million(?=[:upper:])")) 

allocations <- allocations %>%
  mutate(doses_allocated = str_remove_all(doses_allocated, "[,\\s]")) %>% 
  mutate(doses_allocated = ifelse(str_detect(doses_allocated, "(?i)million"), 
                                 as.numeric(trimws(str_remove_all(doses_allocated, "(?i)million")))*1000000,
                                 as.numeric(trimws(doses_allocated))))

allocations <- allocations %>%
  mutate(vaccine_allocated = str_extract(doses_allocated_text, "(?<=\\d)\\s+.*(?=$)") %>% str_remove_all("million") %>% trimws())

driver$navigate(allocations$link[which(!str_detect(allocations$vaccine_allocated, '[[:alpha:]]'))][1]) ## Not all webpages specify which vaccine product has been allocated to the country

driver$close() ## Close the driver (not needed anymore)

rD$server$stop() ## Stop the server

allocations <- allocations %>%
  mutate(vaccine_allocated = ifelse(
    !str_detect(vaccine_allocated, "[[:alpha:]]"),
    NA,
    vaccine_allocated
  ))

allocations <- allocations %>%
  mutate(vaccine_allocated = str_replace_all(vaccine_allocated, "^ ", ""))

allocations <- allocations %>%
  select(-doses_allocated_text, -link, -text)

# Join data

received <- received %>%
  mutate(type = "Received") %>%
  rename("amount" = doses_received,
         "vaccine" = vaccine_received)

allocations <- allocations %>%
  mutate(type = "Allocation") %>%
  rename("amount" = doses_allocated,
         "vaccine" = vaccine_allocated)

covax_deliveries <- full_join(received, allocations)

# Final cleanup

covax_deliveries <- covax_deliveries %>%
  mutate(vaccine = str_remove_all(vaccine, "^\\s+"))

# Example analysis

covax_deliveries %>%
  group_by(country) %>%
  summarize(sum(amount[which(type == "Received")])/sum(amount[which(type == "Allocation")])*100) %>% View() 

```

## Real world example -- data exploration and analysis (GY)

Regex comes in handy for many situations. Beyond data cleaning and gathering, regex can be used when exploring and analyzing data. The below example shows how regex can be used to analyze data. The below example is especially useful for those who work with claims data and builds off previous lessons on apply statements. 

```{real life example data analysis, echo = T}

# Some examples that use claims data. This is a simulated dataset from the pccc package with 1000 observations (id 1:1000).  Each row has 10 columns with icd10 diagnosis codes (dx1:dx10), 10 icd10 procedure codes (pc1:pc10), and 10 columns with randomn numeric values (g1:g10). Think of these as perhaps the dollar amount or the whole claim or cost sharing components, etc.  
# The examples here use regular expressions to select rows, to count the number of times certain diagnoses occur overall or in a claim, and to select the columns of interest.
# 
# You can look at ICD10 codes for free here (these are the fracture codes used below: https://www.icd10data.com/ICD10CM/Codes/S00-T88/S70-S79/S72/S72.0-

# install the package with the dataset
# install.packages("pccc")
library(data.table)
library(pccc)

# assign dataset to p
p <- pccc::pccc_icd10_dataset

# make it a data.tab;e
p <- data.table::setDT(p)

# Use the first diagnosis to choose claims. We will consider dx1 as the primary one for this. We will then cycle through all of the 10 diagnoses
# in icd10, neoplasm codes start with C or D.  All codes starting with C are malignant neoplasms; codes that start with D00 through D49 are benign neoplasms. Codes that start with those letter/number combinations but have more digits are subsets, so D2121 is in the D21 set of codes. Codes of D50 are other types of blood disease so we do not want them
# Count rows where dx1 is malignant neoplasm
p[ grepl("^C", dx1), .N]

# These are the codes
grep("^C", p$dx1, value = T )

# get all of the neoplasms; the ^D[0-4] selects codes that begin with capital D and where the next digit is 0 through 4
p[ grepl("^C|^D[0-4]", dx1), .N]

grep("^C|^D[0-4]", p$dx1, value = T)

# so if g1 was the total cost of the claim, you could sum the costs for these row
p[ grepl("^C|^D[0-4]", dx1), sum(g1, na.rm =T)]

# lets say you wanted to identify cases where there is a neoplasm code in any of the first five diagnosis columns (dx1:dx5). count
# first create a variable that counts the number of the dx columns begins the C in each row.  This basically loops the columns in the .SDcols through the reduce function, which sums the number of times the function is true. 
p[ , sum_neop_5 := Reduce( `+` , lapply( .SD , function(w) grepl("^C|^D[0-4]", w ))), 
	.SDcols = c("dx1", "dx2", "dx3", "dx4", "dx5")]

p[ , .N, keyby = sum_neop_5]

# same but for all 10 columns, use grep rather than writing all the column names
p[ , sum_neop_all := Reduce( `+` , lapply( .SD , function(w) grepl("^C|^D[0-4]", w ))), 
	.SDcols = grep("dx", names(p), value = T)]

p[ , .N, keyby = sum_neop_all]

# or to select the rows
p[ sum_neop_all > 0, .N]

# sum across family or multiple claims.  If the data had multiple claims for a person or family you could
# create a variable that aggregates the number of claims with neoplasms over the family
# group each five rows into "families"
p[ , famid := cut(id, breaks = 200, labels = FALSE)]

p[ , sum_neop_fam := sum(sum_neop_all, na.rm = T), by = famid]

p[ !duplicated(famid), .N, keyby = sum_neop_all]

# match a more specific diagnosis. fractures of the femur start with ^S72. codes that end in H indicate open fractures of type I or II with delayed healing.  the digits after the 2 and before the H indicate where the fracture is (lower or upper end, etc) and some other information.
# just select case where dx1 matches, first 5 columns
p[ grepl("^S72[[:digit:]]+H$", dx1), 1:5]

# end in H or Q
p[ grepl("^S72[[:digit:]]+(H|Q)$", dx1), 1:5]
 

```

