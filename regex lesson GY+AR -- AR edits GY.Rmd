---
title: "String Manipulations and Regular Expressions"
author: "Greg Young and Anna Rouw"
date: "2021-06-30 and last compiled `r Sys.time`"
output: output_format: html_format
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Libraries and Functions

library(tidyverse)
library(rvest)
library(countrycode)

`%!in%` <- Negate("%in%")

```

# Introduction (GY + AR)

In this lesson, we will go over some basic string manipulations (using the packages base and stringr), regular expressions, and a few examples. This hopefully will help when cleaning/manipulating using character data. For a cheatsheet on stringr and regular expressions, see here: <https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_strings.pdf>.


```{r Introduction, include=FALSE}
# I dont know if this section will need any code

```

# Subsetting

This section shows some basic subsetting of a data frame.  It uses some regex to do it.  It is not specific to regex but may be a usefull refference for people.

```{r subseting, include=FALSE}

mtnames <- names(mtcars)

# returns indicies
grep("^d", mtnames)

# returns logic vector
grepl("^d", mtnames)

# returns subset of original vector
mtnames[grep("^d", mtnames)] 
mtnames[grepl("^d", mtnames)] 

# returns subset of columns of dataframe 
mtcars[,grep("^d", names(mtcars))] 

# returns subset of rows of dataframe 
mtcars[grep("^D", rownames(mtcars)),] 

# why is this wrong? 
mtcars[grep("^d", names(mtcars)),] 

# the same thing using data table 
dtcars <- as.data.table(mtcars)
dtcars[,.SD,.SDcols = grep("^d",names(dtcars))]

```


```{r String Manipulations, include=FALSE}
# String Manipulations (GY)

#For a conversion of functions between base and stringr, see here: <https://stringr.tidyverse.org/articles/from-base.html>.

## Code below
### A few ideas on string functions to include: detecting patterns, trimming, locating/extracting, splitting, and replacing.
### Can include both base and stringr, but no need to focus too much time on these. 


# conversion_example <- c("new jersey", "south carolina ", "southern california", "nebraska", "new york", "new mexico", "pennsylvania", "south dakota")
conversion_example <- c("new jersey", "south carolina ", "southern california", "nebraska")#, "new york", "new mexico", "pennsylvania", "south dakota")

# base
gregexpr("new", conversion_example)	
# stringr
str_locate_all(conversion_example, "new")

# base
grep("south", conversion_example, value = TRUE)	
# stringr
str_subset(conversion_example, "south")

# base
grep("south", conversion_example)	
# stringr
str_which(conversion_example, "south")

# base
grepl("south", conversion_example)	
# stringr
str_detect(conversion_example, "south")

# base
gsub("south", "funfunfun", conversion_example)	
# stringr
str_replace_all(conversion_example, "south", "funfunfun")

# base
nchar(conversion_example)	
# stringr
str_length(conversion_example)

# base
order(conversion_example)	
# stringr
str_order(conversion_example)

# conversion str_match
# base
regexec( "south", conversion_example, perl = TRUE ) 
yes <- regexec( "south", conversion_example, perl = TRUE ) 
regmatches(conversion_example, yes)
# stringr
str_match( conversion_example ,"south")


# conversion str_extract
# base
yes <- regexpr( "south", conversion_example, perl = TRUE ) 
regmatches(conversion_example, yes)
# stringr
str_extract( conversion_example ,"south")


# conversion str_locate 
# base
regexpr( "south", conversion_example, perl = TRUE ) 
# stringr
str_locate(conversion_example , "south")

# base
sort(conversion_example)	
# stringr
str_sort(conversion_example)

# base
strrep(conversion_example, n)	
# stringr
str_dup(conversion_example, n)

# # needs more illistrative example vector
# # base
# strsplit(conversion_example, "south")	
# # stringr
# str_split(conversion_example, "south")

# # website example is more illistrative 
# # base
# strwrap(conversion_example)	
# # stringr
# str_wrap(conversion_example)

# base
sub("south", "funfunfun", conversion_example)	
# stringr
str_replace(conversion_example, "south", "funfunfun")

# base
substr(conversion_example, 2, 4)	
# stringr
str_sub(conversion_example, 2, 4)

# base
tolower(conversion_example)	
# stringr
str_to_lower(conversion_example)

# base
tools::toTitleCase(conversion_example)	
# stringr
str_to_title(conversion_example)

# base
toupper(conversion_example)	
# stringr
str_to_upper(conversion_example)

# base
trimws(conversion_example)	
# stringr
str_trim(conversion_example)


```


# Regular Expressions (AR)

Regular expressions are a sequence of special characters to describe a text pattern. Regular expressions are not unique to R and are used across programming languages. We'll go over types of regular expressions before getting into more complicated examples. 

```{r regex, echo = T}

## Code below
### Ideas we talked about for topics to include: anchors, quantifiers, character classes, escaping, look-around, anti-matches, case insensitive, grouping  

# Anchors
## Anchors allow you to find patterns at the start or end of a string

anchors_example <- c("January", "February", "March", "April", "May", "June", "July", "August", "September", "October", "November", "December")

anchors_example[str_detect(anchors_example, "^J")] ## Find months that start with the letter J
anchors_example[str_detect(anchors_example, "er$")] ## Find months that end in 'er'

# Quantifiers
## Quantifiers allow you to define how many times to look for a certain pattern

quantifiers_example <- c("1", "2", "30000", "45600", "7836539273", "45", "150", "Anna")

str_extract(quantifiers_example, "[[:digit:]]?") ## Find digit of 0 or 1 length 
str_extract(quantifiers_example, "[[:digit:]]*") ## Find digit of any length (including 0)
str_extract(quantifiers_example, "[[:digit:]]+") ## Find digit of at least 1 length (does not include 0)
str_extract(quantifiers_example, "[[:digit:]]{2}") ## Find digit with at least 2 length
str_extract(quantifiers_example, "[[:digit:]]{3,}") ## Find digits greater than 99
str_extract(quantifiers_example, "[[:digit:]]{3,6}") ## Find digits with lengths between 3 and 6

# Match characters
## There are certain, pre-defined match characters that look for certain character types in a string.

match_character_example <- c("Alabama, 5%", "Florida 10.7%", "Colorado 7.1%", "West Virginia, 15.7%") 

### Numbers

str_extract_all(match_character_example, "[[:digit:]]+") ##Breaks up values when interrupted by another character type

### Punctuation

str_extract_all(match_character_example, "[[:punct:]]+")

### Letters

str_extract_all(match_character_example, "[[:alpha:]]+")

### Spaces

str_extract_all(match_character_example, "[[:space:]]+")

### Any character (except new lines -- \n)

str_extract(match_character_example, ".+")

### Other types -- lowercase, uppercase, blanks (tabs and spaces) and combinations (i.e. [[:alnum:]])


# Escaping
## Some characters, such as the $ anchor, are used to denote other patterns and do not represent the symbol itself. These characters, in order to be captured, must be escaped. We escape using the \

escape_example <- c("$4500", "(Hello)", "What is your favorite movie?")

str_extract(escape_example, "$")
str_extract(escape_example, "\\$")
str_extract(escape_example, "?")
str_extract(escape_example, "\\?")
str_extract(escape_example, "(")
str_extract(escape_example, "\\(")

## \ can also be used to describe a character type, such as digits or words.

escape_words_example <- "Dogs are the best"

str_extract_all(escape_words_example, "\\w+") ## Extracts all the words from the sentence.

# Look Arounds
## Look-arounds are very helpful to identify patterns before and/or after a certain string. 
### Look behind

look_behind_example <- c("KFF Employee ID: 98", "KFF Employee ID: 72", "KFF Employee ID: 43")

str_extract(look_behind_example, "(?<=KFF Employee ID: ).*")

## Look ahead

look_ahead_example <- c("Mr. Sam Smith", "Dr. Anthony Fauci", "Mrs. Rita Rooney")

str_extract(look_ahead_example, ".*\\.(?= )")

# Groups
## Grouping allows us to set order of evaluation when looking for patterns and add a bit of flexibility.

grouping_example <- c("Violet", "Vince", "Charlie", "Terry", "Vance", "Tanya", "Vicky Vaughn")

str_extract(grouping_example, "^(V|T).*") ## Find names that start with V or T

str_extract(grouping_example, "^(V).*\\1.*") ## Allows us to reference previously created groups, which are defined by the parentheses,

# Case Insensitivity
## Ignore case

case_insenstive_example <- c("Medicare", "medicare")

str_extract(case_insenstive_example, "(?i)medicare")

# Alternates
## Set parameters around your search

alternates_example <- c("890-450-3583", "annar@kff.org", "1330 G St.", "Corgis are the best dogs")

### Or logical operator

str_extract(alternates_example, "\\d+|[:punct:]+") ## Find first set of digits or punctuation

### One of

str_extract(alternates_example, "[[:digit:][:punct:][:space:]]+") ## Lets you combine specific character types

### Anything but

str_extract(alternates_example, "[^[:alpha:]]+")

### Range

str_extract(alternates_example, "[a-z]+")


```

# Examples (GY)

Probably will need to shorten this section a bit. 

```{r examples, echo = T}

# id numbers 
id <- c("ID3445","WRT-3445","W3D-3445", "YH893","WR-902","WY9323","AO-394","A2-394","W2-657","ER-323","WP-434","YP-434")

# returns every element starting with a Y
id[grep("^Y", id)] 
# returns every element starting with W followed by 1 letter and then a dash
id[grep("^W[[:alpha:]]-", id)] 
# returns every element starting with W followed by 1 or more letters and then a dash
id[grep("^W[[:alpha:]]+-", id)] 
# returns every element starting with W followed by any 1 character and then a dash
id[grep("^W.-", id)]
# returns every element starting with W followed by 1 or more of any character and then a dash
id[grep("^W.+-", id)]
# ```


# get the whole numbers
wn <- c("173.34","Deductible $1200", "21", "Copay")

# extracts the whole number portion of element
str_extract( wn ,"\\d+") 
# extracts first two digits of element
str_extract( wn ,"\\d{2}") 
# extracts last digit of element
str_extract( wn ,"\\d{1}$") 
# escape dollar sign
str_extract( wn ,"\\$\\d+") 
# escape dollar sign optional
str_extract( wn ,"\\$?\\d+") 
# extracts first word of element
str_extract( wn ,"[[:alpha:]]+") 



# correct state names
s <- c("District of\nColumbia", "South Carolina ","Texas", "Hawaii 50")

# replaces "\n"
str_replace_all(s, "\n", " ")  
# replaces all alphabetic characters
str_replace_all(s, "[[:alpha:]]", " ") 
# replaces all non alphabetic characters
str_replace_all(s, "[^[:alpha:]]", " ") 

str_extract( s ,"[[:alpha:]]+") 



# get rid of the missing zip
zips <- c("98300","02390","No Zip")

ifelse( grepl("\\d{5}", zips), zips , "" )


# find the dr
x <- c("Dr Dre","Drought", "ADr", "soft drink", "soft ball", "drink draft beer", "Dr Dre drinks draft beer", "MC Hammer likes Pepsi", "Conor McGregor drinks Whiskey")

grep("Dr", x)
x[grep("Dr", x)]
grep("dr", x)
x[grep("dr", x)]
x[grep("(?i)dr", x)]


# convert this to numbers
n <- c("1.2%","1.0%","3.9%","1.9%","5.6%","3.4%")

as.numeric(str_replace_all(n, "%", ""))
as.numeric(str_replace_all(n, "%", ""))/100


# convert multiple underscores into one underscore
x <- c( "var_1","var__2","var____3" ,"anoter_var__3")

# using str_replace_all
str_replace_all( x ,"[[:punct:]]+", "_")
# using gsub
gsub("[[:punct:]]+", "_", x)
# replace underscore with dot (the dot can be very convient for later on)
gsub("[[:punct:]]+", ".", x)


# extract value with look arounds
prem <- c("HMO Premium 456","HMO Premiums 789","Premiums are 345","999 Premiums this year are 443","555 Premiums this year were payed", "Deductible of 721 this year")

#use look behind for premium
str_extract( prem ,"(?<=Premium.{1,30}\\d{0})\\d+")
#use look behind for deductible
str_extract( prem ,"(?<=Deductible.{1,30}\\d{0})\\d+")
#use look ahead for number of premium
str_extract( prem ,"(?=.{1,30}Premium)\\d+")


### get rid of punctuation and numbers
wp <- c("Hospital.Names...3","State_ ", "George")

str_replace_all(wp, "[._ \\d]", " ")
str_replace_all(wp, "[._ \\d]+", " ")
str_replace_all(wp, "[[[:punct:]]]+", " ")
str_replace_all(wp, "[[[:punct:]]\\d]+", " ")
str_replace_all(wp, "[[[:punct:]]\\d\\s]+", " ")


### Convert this to a five digit zip code
zip <- c("91367-6798","91364-2792","4605-2792")

str_pad(str_extract( zip ,"\\d+(?=-)"), 5, pad = "0") 
str_pad(str_extract( zip ,"\\d+(?=-\\d{4})"), 5, pad = "0")


### Reduce this to First and last names 
fl <- c("Matthew T. Rae","Claxton, Gary", "Dr. Craig Palosky Esq.", "Dr. Chris Lee", "Damico, Anthony","Daniel McDermott Jr.")

# first names

str_trim(str_extract( fl ,"[[:Alpha:]]+\\s|[[:Alpha:]]+$"), side ="both") 
# first and last names
str_replace_all(str_trim(str_replace_all(fl, "[[:alpha:]]{1,3}\\.", ""), side ="both"), "[[:punct:]]", "")


# more lookarounds 
y <- c("Ruffles is the most handsome dog", "Max is the happiest Dog", "Kellie likes cats","Bob has dogs and cats")# more complicated 

# First word of string with the word dog
str_extract( y ,"^[[:Alpha:]]+(?=.{1,30}(?i)dog)") 
# Second word of string with the word dog
str_extract( y ," [[:Alpha:]]+(?=.{1,30}(?i)dog)") 
# First word of string with the word cat
str_extract( y ,"^[[:Alpha:]]+(?=.{1,30}(?i)cat)") 


# grouping - when you place parenthesis around something it keeps it as a seperate group 
# phone numbers 
pn <- c("202-555-4343","202-555-8434","555-8434","(434)555-4567","434-555-4567","434-555-4347","(202)555-4567","434-555-4347","(202)555-4567")

# recode phone numbers so they are in same format
pn <- str_replace_all(str_replace_all(pn, "\\(" , ""), "\\)", "-")  

# remove phone numbers missing area code # be carefull 
pn <- ifelse(grepl("\\d{3}-\\d{3}-\\d{4}", pn), pn , NA) 

# redact last 7
str_replace_all(pn, "(\\d{3})-(\\d{3})-(\\d{4})", "\\1-xxx-xxxx")  
# redact last 4 
str_replace_all(pn, "(\\d{3})-(\\d{3})-(\\d{4})", "\\1-\\2-xxxx") 
# redact middle 3
str_replace_all(pn, "(\\d{3})-(\\d{3})-(\\d{4})", "\\1-xxx-\\3")  

# extract area code of washington numbers
str_replace_all(str_extract(pn, "^202|^.202"), "\\(" , "") 
# extract all area codes
str_replace_all(pn, "(\\d{3})-(\\d{3})-(\\d{4})", "\\1")   




# counting patters 
t <- c( "Yankees","Red Sox", "South Central Yard Dawgs", "2019 National League Pennant winning Washington Nationals")
t
# count specific letter pattern 
str_count(t, pattern = "al")
# count word boundaries ( 2 x number of words)
str_count(t, pattern = "\\b") 
# count all groups of alphabetic characters bounded by non alphabetic characters (words)
str_count(t, pattern = "[[:alpha:]]+") 
# count all groups of alphanumeric characters bounded by non alphanumeric characters 
str_count(t, pattern = "[[:alnum:]]+") 
# display just first word
str_replace_all(t, "([[:alnum:]]+) ([[:alnum:]]+).+", "\\1")
# display just second word
str_replace_all(t, "([[:alnum:]]+) ([[:alnum:]]+).+", "\\2")  #easy but not 100% 
# try buliding it up in peaces
# first
str_extract(t, "(^[[:alnum:]]+\\b)" ) 
# second
str_extract(t, "((?<=\\s)[[:alnum:]]+\\b)" ) 
# combine the two
str_replace_all(t, "(^[[:alnum:]]+\\b) ((?<=\\s)[[:alnum:]]+\\b)", "\\2") # still not it





# split phone numbers into new variables 
df <- data.frame(pn = c("202-555-4343","202-555-8434","555-8734","(434)555-4567","434-555-4567","434-555-4347","(583)555-4567","434-555-4347"))

df %>% 
	mutate(pn = str_replace_all(pn, "\\(", "")) %>% 
	separate(pn, c("A","B","C"), sep = "([\\)-])", fill = "left")

```

## Real world example (AR)

Going to be pulling data from each country's COVAX delivery web page. For reference, here is what Afghanistan's web page looks like: <https://www.gavi.org/covax-vaccine-roll-out/afghanistan>. The web pages have already been scraped for each country, but we will use string manipulations and regular expressions to extract the data from the messy text.

```{r real life example set up, include = F}

covax_deliveries_url <- 'https://www.gavi.org/covax-vaccine-roll-out'

covax_deliveries <- covax_deliveries_url %>%
  read_html() %>%
  html_nodes("a") %>%
  html_attr('href') %>%
  as_tibble() %>%
  filter(str_detect(value, "covax-vaccine-roll-out/")) %>% 
  unique() %>% 
  mutate(link = paste0("https://www.gavi.org", value)) %>%
  select(-value) %>%
  mutate(country = str_extract(link, "(?<=out/).*(?=$)")) %>%
  mutate(country = countrycode::countrycode(country, origin = 'country.name', destination = 'country.name.en', nomatch = country))

doses <- data.frame()

for (x in covax_deliveries$link) {
  text <- x %>%
    read_html() %>%
    html_nodes(".content") %>%
    html_text()%>%
    as_tibble() 
  
  text <- text$value[2]

  new_doses <- data.frame(
    "text" = text,
    "link" = x)
  
  doses <- rbind(doses, new_doses)
}

doses <- doses %>%
  group_by(link) %>%
  filter(str_detect(text, 'First')) %>%
  ungroup()

doses <- doses %>%
  mutate(text = str_replace_all(text, "\\\n|\\\t", " ")) ## Replace new lines

doses <- doses %>%
  mutate(text = str_remove_all(text, "Statement.*(?=$)"))

rm(covax_deliveries, covax_deliveries_url, new_doses, text, x)

```

```{r real life example, echo = T}

# Get country name from link

doses <- doses %>%
  mutate(country = str_to_title(str_extract(link, "(?<=out/).*(?=$)"))) %>%
  arrange(country)

doses <- doses %>%
  mutate(country = countrycode(country, origin = 'country.name', destination = 'country.name.en', nomatch = country)) ## clean up country names

# Get date of first delivery

doses$text[1]

doses <- doses %>%
  mutate(first_delivery_date = str_extract(text, "\\d{1,2}\\s{1}[[:alpha:]]*\\s{1}\\d{4}"))

doses <- doses %>%
  mutate(first_delivery_date = as.Date(first_delivery_date, format = "%d %B %Y")) ## Convert to a date. For reference, here are the date formats: https://www.r-bloggers.com/2013/08/date-formats-in-r/


# Find doses received

received <- doses %>%
  mutate(doses_received_text = str_extract(text, "(?<=Doses received).*(?=Doses allocated)") %>% trimws())

received <- received %>%
  separate_rows(doses_received_text, sep = "vaccine") 

received <- received %>%
  filter(str_detect(doses_received_text, "\\d"))

received <- received %>%
  mutate(doses_received = str_extract_all(doses_received_text, "\\d{1,3},\\d{3},\\d{3}|\\d{1,3},\\d{3}|\\d{1,3}\\.\\d{1,3}\\s{1}(?i)million|\\d{1,3}\\s{1}(?i)million(?=[:upper:])")) 

received <- received %>%
  mutate(doses_received = str_remove_all(doses_received, "[,\\s]")) %>% 
  mutate(doses_received = ifelse(str_detect(doses_received, "(?i)million"), 
                                 as.numeric(trimws(str_remove_all(doses_received, "(?i)million")))*1000000,
                                 as.numeric(trimws(doses_received))))

received <- received %>%
  mutate(vaccine_received = str_extract(doses_received_text, "(?<=\\d)\\s+.*(?=$)") %>% str_remove_all("million") %>% trimws())

received <- received %>%
  select(-doses_received_text, -link, -text) ## Do not need anymore

# Find doses allocated

allocations <- doses %>%
  mutate(doses_allocated_text = str_extract(text, "(?<=Doses allocated).*(?=$)"))

allocations <- allocations %>%
  separate_rows(doses_allocated_text, sep = "vaccine")

allocations <- allocations %>%
  filter(str_detect(doses_allocated_text, "\\d"))

allocations <- allocations %>%
  mutate(doses_allocated = str_extract_all(doses_allocated_text, "\\d{1,3},\\d{3},\\d{3}|\\d{1,3},\\d{3}|\\d{1,3}\\.\\d{1,3}\\s{1}(?i)million|\\d{1,3}\\s{1}(?i)million(?=[:upper:])")) 

allocations <- allocations %>%
  mutate(doses_allocated = str_remove_all(doses_allocated, "[,\\s]")) %>% 
  mutate(doses_allocated = ifelse(str_detect(doses_allocated, "(?i)million"), 
                                 as.numeric(trimws(str_remove_all(doses_allocated, "(?i)million")))*1000000,
                                 as.numeric(trimws(doses_allocated))))

allocations <- allocations %>%
  mutate(vaccine_allocated = str_extract(doses_allocated_text, "(?<=\\d)\\s+.*(?=$)") %>% str_remove_all("million") %>% trimws())

allocations <- allocations %>%
  mutate(vaccine_allocated = ifelse(
    !str_detect(vaccine_allocated, "[[:alpha:]]"),
    NA,
    vaccine_allocated
  ))

allocations <- allocations %>%
  mutate(vaccine_allocated = str_replace_all(vaccine_allocated, "^ ", ""))

allocations <- allocations %>%
  select(-doses_allocated_text, -link, -text)

# Join data

received <- received %>%
  mutate(type = "Received") %>%
  rename("amount" = doses_received,
         "vaccine" = vaccine_received)

allocations <- allocations %>%
  mutate(type = "Allocation") %>%
  rename("amount" = doses_allocated,
         "vaccine" = vaccine_allocated)

covax_deliveries <- full_join(received, allocations)

# Final cleanup

covax_deliveries <- covax_deliveries %>%
  mutate(vaccine = str_remove_all(vaccine, "^\\s+"))

# Example analysis

covax_deliveries %>%
  group_by(country) %>%
  summarize(sum(amount[which(type == "Received")])/sum(amount[which(type == "Allocation")])*100) %>% View() 


```
